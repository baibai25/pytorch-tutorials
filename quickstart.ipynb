{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caf53af1-112d-4a01-8bd8-d30df5f45193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b26e49f9-36a8-4d3b-8d2d-e7a9273182fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a5cc1b-ba60-41ee-b249-c4eaa62aaf1b",
   "metadata": {},
   "source": [
    "## Working with data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8538c966-1e7a-4356-984d-b1a72afcbce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1576813dd54fd7b2b2a59fbbe02288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2def2cb3a084c878ea13412e39bc796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b73ccf6bb54a1486ac4a84e8d1a60b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f3f6fd766545148cc99b1b7695a81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3a84830-2006-47b8-9065-04f592445e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "  print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "  print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56cbf99c-f88e-4207-8a19-ce8ed27fd49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nN: number of instaces\\nC: channel?\\nH: height\\nW: width\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "N: number of instaces\n",
    "C: channel?\n",
    "H: height\n",
    "W: width\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107a8f4b-dd7e-47e9-94d9-4eaa15a8fee9",
   "metadata": {},
   "source": [
    "## Creating Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "174fd81d-1637-4aac-a074-7d3e5ebed2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# simple situation\n",
    "# Ref. https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e656e0bf-89d8-460d-b5a3-f61eb43bd871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n",
      "tensor([[0.5433, 0.3418, 0.3888,  ..., 0.7980, 0.4069, 0.6479],\n",
      "        [0.8799, 0.4713, 0.9816,  ..., 0.7971, 0.1539, 0.3975],\n",
      "        [0.6140, 0.8910, 0.6566,  ..., 0.3116, 0.2316, 0.9055]])\n"
     ]
    }
   ],
   "source": [
    "# flatten -> [3, 28*28]\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())\n",
    "print(flat_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ded0a86-1679-4de3-9865-31ab63e73fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n",
      "tensor([[ 0.1342,  0.2033,  0.5575,  0.4375,  0.2087,  0.9226, -0.2905, -0.3054,\n",
      "          0.8958,  0.0459, -0.2880, -0.1285,  0.0481, -0.0102, -0.4472, -0.2859,\n",
      "         -0.0291,  0.2186, -0.7362,  0.1767],\n",
      "        [ 0.0621,  0.5183,  0.1368,  0.1004,  0.4541,  0.8500, -0.3177, -0.2868,\n",
      "          0.5549,  0.2838,  0.1924, -0.1075, -0.1319,  0.2031, -0.5142, -0.2983,\n",
      "         -0.3614,  0.0679, -0.2935,  0.3441],\n",
      "        [-0.0605,  0.4426,  0.2652,  0.2357, -0.1846,  0.9035, -0.4481, -0.3386,\n",
      "          0.4510,  0.2209, -0.4812, -0.1850,  0.1147,  0.4927, -0.3544,  0.1058,\n",
      "         -0.2763,  0.0252,  0.0142,  0.1597]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# value * weight\n",
    "layer1 = nn.Linear(in_features=28 * 28, out_features=20)  # fully connected\n",
    "hidden1 = layer1(flat_image)  # linear transformation (calc hiddlen unit value)\n",
    "print(hidden1.size())\n",
    "print(hidden1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "38dcfa83-5b13-4e35-ba51-6183a2e2d9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 784])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0169,  0.0224, -0.0092,  ..., -0.0342, -0.0003, -0.0029],\n",
      "        [ 0.0070,  0.0247,  0.0296,  ..., -0.0203, -0.0153,  0.0154],\n",
      "        [ 0.0179, -0.0333,  0.0020,  ...,  0.0304, -0.0271, -0.0342],\n",
      "        ...,\n",
      "        [ 0.0260,  0.0102, -0.0124,  ..., -0.0323, -0.0275,  0.0302],\n",
      "        [-0.0012,  0.0190,  0.0074,  ..., -0.0222, -0.0289,  0.0214],\n",
      "        [ 0.0320, -0.0232,  0.0066,  ..., -0.0310, -0.0304,  0.0249]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0356, -0.0334,  0.0222,  0.0215, -0.0271, -0.0328,  0.0328,  0.0145,\n",
      "         0.0065,  0.0352,  0.0205, -0.0083, -0.0219,  0.0131,  0.0020,  0.0142,\n",
      "        -0.0316, -0.0156,  0.0204, -0.0274], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# weight\n",
    "print(layer1.weight.shape)\n",
    "print(layer1.weight)\n",
    "\n",
    "# bias\n",
    "print(layer1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcd12224-6abb-466f-823e-5a1d5f7bd0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.2276, 0.0755, 0.0000, 0.0699, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.2862, 0.0113, 0.0000, 0.0000, 0.3345, 0.0000, 0.0000,\n",
      "         0.4429, 0.0000],\n",
      "        [0.0223, 0.3098, 0.3799, 0.0000, 0.0000, 0.1425, 0.0000, 0.2542, 0.0000,\n",
      "         0.0000, 0.0000, 0.6239, 0.0000, 0.0000, 0.0000, 0.5216, 0.0316, 0.0000,\n",
      "         0.2692, 0.0000],\n",
      "        [0.0000, 0.1740, 0.1599, 0.0000, 0.0490, 0.0105, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.2655, 0.0000, 0.0000, 0.0000, 0.4099, 0.0000, 0.0000,\n",
      "         0.0428, 0.0000]], grad_fn=<ReluBackward0>)\n",
      "compare: \n",
      " [[0.         0.22763467 0.07549297 0.         0.06993171 0.\n",
      "  0.         0.         0.         0.         0.         0.2861728\n",
      "  0.01131467 0.         0.         0.33452192 0.         0.\n",
      "  0.44294244 0.        ]\n",
      " [0.02233453 0.30984586 0.3798543  0.         0.         0.14248651\n",
      "  0.         0.25422323 0.         0.         0.         0.6239005\n",
      "  0.         0.         0.         0.52158266 0.0315935  0.\n",
      "  0.26915962 0.        ]\n",
      " [0.         0.17402744 0.15986314 0.         0.04900331 0.0105173\n",
      "  0.         0.         0.         0.         0.         0.26554945\n",
      "  0.         0.         0.         0.40992305 0.         0.\n",
      "  0.04281331 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# ReLU\n",
    "hidden_activate = nn.ReLU()(hidden1)\n",
    "print(hidden_activate)\n",
    "\n",
    "\n",
    "# compare\n",
    "def relu(x):\n",
    "  return np.maximum(0, x)\n",
    "\n",
    "\n",
    "print('compare: \\n', relu(hidden1.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90da4157-1675-48ab-97d8-e6c62152c1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "'''\n",
    "To define a neural network in PyTorch, we create a class that inherits from nn.Module.\n",
    "We define the layers of the network in the __init__ function and specify how data will pass through the network in the forward function. \n",
    "'''\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(NeuralNetwork, self).__init__()\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.linear_relu_stack = nn.Sequential(nn.Linear(28 * 28, 512), nn.ReLU(),\n",
    "                                           nn.Linear(512, 512), nn.ReLU(),\n",
    "                                           nn.Linear(512, 10))\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.flatten(x)\n",
    "    logits = self.linear_relu_stack(x)\n",
    "    return logits\n",
    "\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c12120-bd2e-4e74-890f-b00d24a6e1b4",
   "metadata": {},
   "source": [
    "## Optimizing the Model Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb5dfad4-dc1f-4a0f-8e3f-8fe8e2a162c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba40b6ed-9e45-4e2c-b801-398bf950df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "  size = len(dataloader.dataset)\n",
    "  model.train()\n",
    "\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "\n",
    "    # Compute prediction error\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      loss, current = loss.item(), batch * len(X)\n",
    "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34e24f24-d06b-4694-b5a1-d843789844c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "  size = len(dataloader.dataset)\n",
    "  num_batches = len(dataloader)\n",
    "  model.eval()\n",
    "  test_loss, correct = 0, 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for X, y in dataloader:\n",
    "      X, y = X.to(device), y.to(device)\n",
    "      pred = model(X)\n",
    "      test_loss += loss_fn(pred, y).item()\n",
    "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "  test_loss /= num_batches\n",
    "  correct /= size\n",
    "\n",
    "  print(\n",
    "      f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "692760a9-4d02-4029-a911-e5a57884d308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.309794  [    0/60000]\n",
      "loss: 2.296753  [ 6400/60000]\n",
      "loss: 2.275776  [12800/60000]\n",
      "loss: 2.262720  [19200/60000]\n",
      "loss: 2.258513  [25600/60000]\n",
      "loss: 2.221460  [32000/60000]\n",
      "loss: 2.226047  [38400/60000]\n",
      "loss: 2.197746  [44800/60000]\n",
      "loss: 2.191819  [51200/60000]\n",
      "loss: 2.158185  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 46.0%, Avg loss: 2.156168 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.167736  [    0/60000]\n",
      "loss: 2.167184  [ 6400/60000]\n",
      "loss: 2.103154  [12800/60000]\n",
      "loss: 2.116186  [19200/60000]\n",
      "loss: 2.080446  [25600/60000]\n",
      "loss: 2.006286  [32000/60000]\n",
      "loss: 2.038419  [38400/60000]\n",
      "loss: 1.960451  [44800/60000]\n",
      "loss: 1.958233  [51200/60000]\n",
      "loss: 1.896353  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.2%, Avg loss: 1.892941 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.922152  [    0/60000]\n",
      "loss: 1.911476  [ 6400/60000]\n",
      "loss: 1.779484  [12800/60000]\n",
      "loss: 1.820993  [19200/60000]\n",
      "loss: 1.723938  [25600/60000]\n",
      "loss: 1.656347  [32000/60000]\n",
      "loss: 1.683232  [38400/60000]\n",
      "loss: 1.580533  [44800/60000]\n",
      "loss: 1.597725  [51200/60000]\n",
      "loss: 1.504494  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.3%, Avg loss: 1.519093 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.580166  [    0/60000]\n",
      "loss: 1.563364  [ 6400/60000]\n",
      "loss: 1.396105  [12800/60000]\n",
      "loss: 1.477666  [19200/60000]\n",
      "loss: 1.358927  [25600/60000]\n",
      "loss: 1.342636  [32000/60000]\n",
      "loss: 1.362950  [38400/60000]\n",
      "loss: 1.281267  [44800/60000]\n",
      "loss: 1.316637  [51200/60000]\n",
      "loss: 1.226836  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 1.251082 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.324309  [    0/60000]\n",
      "loss: 1.319299  [ 6400/60000]\n",
      "loss: 1.141847  [12800/60000]\n",
      "loss: 1.257757  [19200/60000]\n",
      "loss: 1.133168  [25600/60000]\n",
      "loss: 1.149076  [32000/60000]\n",
      "loss: 1.171717  [38400/60000]\n",
      "loss: 1.104037  [44800/60000]\n",
      "loss: 1.145351  [51200/60000]\n",
      "loss: 1.070282  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.3%, Avg loss: 1.088883 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for t in range(epochs):\n",
    "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "  train(train_dataloader, model, loss_fn, optimizer)\n",
    "  test(test_dataloader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbde72b0-147b-407b-930e-b19956a035e0",
   "metadata": {},
   "source": [
    "## Saving and Loding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2fa59c99-c73b-43d7-ba8f-1838a6e746e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"model.pth\")\n",
    "# print(\"Saved PyTorch Model State to model.pth\")\n",
    "\n",
    "# model = NeuralNetwork()\n",
    "# model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7bac10c-5530-43ae-a009-c7ba9a3c6315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "  pred = model(x)\n",
    "  predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "  print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64337ad6-3838-4081-939d-1357019db617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wip\n",
    "# https://free.kikagaku.ai/tutorial/basic_of_deep_learning/learn/pytorch_basic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
