{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfcf629d-dea8-4988-99ac-79427b250a02",
   "metadata": {},
   "source": [
    "## TENSORS\n",
    "- https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05359b13-0544-4891-a02c-2fe3ab295a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282e0cb9-b925-4fb2-a04a-6108cac8c84b",
   "metadata": {},
   "source": [
    "### Initializing a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66a8a93-6b6a-4b48-84c8-985606d51530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directry from data\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658bc6ea-76e7-4e4e-82ca-c3b15b4680bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ccf292-6741-4c31-94e2-b77f7d2cd5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85f8aaa-0434-4b1b-99c2-97eb1b20f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c6ed6-af2c-4439-8307-1fc39d9011b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all one\n",
    "x_ones = torch.ones_like(x_data)  # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "# random number\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)  # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29538307-30a8-43f9-b640-0705e0ef9053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With random or constant values\n",
    "shape = (\n",
    "    2,\n",
    "    3,\n",
    ")\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b9bc47-69a6-4ffe-b002-8cc3881adb44",
   "metadata": {},
   "source": [
    "### Attributes of a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3875065-11a3-4d54-b689-4f3642972455",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(\n",
    "    f\"Device tensor is stored on: {tensor.device}\"\n",
    ")  # Is the torch.device where this Tensor is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467a8038-12ef-4876-a4ee-9481efa2300a",
   "metadata": {},
   "source": [
    "### Operations on Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7465f383-0f1d-4af9-a61a-c2066e0e95f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We move our tensor to the GPU if available.\n",
    "By default, tensors are created on the CPU.\n",
    "We need to explicitly move tensors to the GPU using .to method.\n",
    "\"\"\"\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c6aa17-d76e-41e0-bf4b-012918cd4b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor形式であってもnumpyの様な配列操作、統計値計算、fillが可能（省略）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f27b7e-9082-4d6f-9b3e-6c955cbff5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5584105-99f6-4d6a-9e1a-0e65bf0c2c00",
   "metadata": {},
   "source": [
    "## DATASETS & DATALOADERS\n",
    "- https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d298ad9b-c412-44b0-96d6-bd648c30fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e2573a-0dfb-4721-a847-d3ec41f03228",
   "metadata": {},
   "source": [
    "### Loading a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1269d47-1f61-4212-934f-5acce2f105f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",  # save path\n",
    "    train=True,  # train or test\n",
    "    download=True,  # if none download from internet\n",
    "    transform=ToTensor(),  # convert data\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",  # save path\n",
    "    train=False,  # train or test\n",
    "    download=True,  # id none download from internet\n",
    "    transform=ToTensor(),  # convert data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d6619c-971a-4062-9120-f4af05adb749",
   "metadata": {},
   "source": [
    "### Iterating and Visualizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f2963e-ed13-4113-aae4-dcff73f65649",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517ec3b4-4350-4c1b-8163-50f12d1493cc",
   "metadata": {},
   "source": [
    "### Creating a Custom Dataset for your files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29f6e9-ee03-4085-acf5-ebb240d771e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    # dataset objectをインスタンス化するときに実行. 各パラメータの初期化\n",
    "    def __init__(\n",
    "        self, annotations_file, img_dir, transform=None, target_transform=None\n",
    "    ):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    # get number of samples\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    # 与えられたindexのデータを取得する\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0539e4-590f-4cb0-a8f0-3e8722c7686b",
   "metadata": {},
   "source": [
    "### Preparing your data for training with DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa9f67c-0e2b-4b46-86b0-8508a96c08cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# シャッフル、batch化をiterableによろしくやってくれる\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eeda66-ef06-45f4-bdb6-c7c88f1c9545",
   "metadata": {},
   "source": [
    "### Iterate through the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3190ded-215e-45b7-949e-3273ef9358af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "# dataloaderにロードしているので、反復処理ができる？　（毎回読む必要がないことを言いたい気がする）\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9e4e1c-198b-4234-b119-0063e3b646ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))  # nextなので次の画像が呼び出される\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4438c49-207b-48ab-89b1-848c52588982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "449144e2-e3d2-4736-910e-ee7ff6ffacb1",
   "metadata": {},
   "source": [
    "## TRANSFORMS\n",
    "- https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64068318-9707-4548-b94a-27c8e543ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import Lambda, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105d591f-9fd6-457f-b5a6-236f7ad6e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The FashionMNIST features are in PIL Image format, and the labels are integers.\n",
    "For training, we need the features as normalized tensors, and the labels as one-hot encoded tensors.\n",
    "To make these transformations, we use ToTensor and Lambda.\n",
    "\"\"\"\n",
    "ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),  # converts a PIL image or NumPy ndarray into a FloatTensor\n",
    "    target_transform=Lambda(\n",
    "        lambda y: torch.zeros(10, dtype=torch.float).scatter_(\n",
    "            0, torch.tensor(y), value=1\n",
    "        )\n",
    "    ),  # one hot encod using lambdafunction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df82b32-b8ff-41d4-9642-e394dd7c1d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9235ed6d-48e8-4442-9621-fa6344624ad8",
   "metadata": {},
   "source": [
    "## BUILD THE NEURAL NETWORK\n",
    "- https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856fc07a-4e9d-48eb-96b7-661421dfd277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead6b13-10d8-48db-9834-c0d44392cea8",
   "metadata": {},
   "source": [
    "### Get Device for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e7aba9-d54f-4af3-8260-744672c0653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6225d8e-655f-4c52-a0b0-68ef6309f492",
   "metadata": {},
   "source": [
    "### Define the Class\n",
    "- `nn.Module`のサブクラスとして定義をする\n",
    "- `__init__`でNNを初期化する\n",
    "- `forward`で伝搬部分の処理を記述する\n",
    "  - kerasは良き感じにここをやってくれていた\n",
    "  - 各レイヤー、ユニット数を決め、伝搬部も記述すると考えると自然ではある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2435fb88-7ce6-4cab-8e55-0be5f1d2eed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b171e1-9019-4a13-b5ca-e5ff8c5b082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 明示的にCPU、GPUどちらで処理をするのか記述\n",
    "# 先に実行計画（モデル）を渡し、入力が来たらそれを実行するイメージ？\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c9d2f1-8e23-43f6-a072-0d45062a6109",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)  # get 10 logits\n",
    "pred_probab = nn.Softmax(dim=1)(logits)  # softmax\n",
    "y_pred = pred_probab.argmax(1)  # get proba\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f7e3f5-d5cb-4da3-8779-849520dc638e",
   "metadata": {},
   "source": [
    "### Model Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c65b48-64c6-47c4-a516-891fe36b50d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44127c0-a467-4d93-b6a7-78b1b9f4f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802b28a8-75ae-400f-8275-ce126840007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear\n",
    "layer1 = nn.Linear(in_features=28 * 28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f110a-2255-4102-a486-d40d8ad086b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relu\n",
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b945a515-c990-4921-a306-4df1bf1fcf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential\n",
    "seq_modules = nn.Sequential(flatten, layer1, nn.ReLU(), nn.Linear(20, 10))\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3ed108-09e3-4dae-9035-5f90dacacd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax\n",
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350ce50b-b4b3-42ff-a04a-74ba2c5943da",
   "metadata": {},
   "source": [
    "### Model Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0997ef44-98b6-4a5f-af89-49e6b1de536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can preview each parameter\n",
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4543fab0-448f-4fc4-a8b7-ea200258af98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e756dd81-f78e-4c76-a9c4-c77a5c2dae96",
   "metadata": {},
   "source": [
    "## Automatic Differentiation with torch.autograd\n",
    "- https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc90055-7469-4717-9c1d-2616196317fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)  # learning param\n",
    "b = torch.randn(3, requires_grad=True)  # learning param\n",
    "z = torch.matmul(x, w) + b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a705656-07da-4776-abd2-c7c07c1d8146",
   "metadata": {},
   "source": [
    "<img src='https://pytorch.org/tutorials/_images/comp-graph.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f882b396-be3a-4e08-8092-bd5fefcf94fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Gradient function for z = {z.grad_fn}\")\n",
    "print(f\"Gradient function for loss = {loss.grad_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1b6135-1af7-4ae0-be0a-43203e87ccd2",
   "metadata": {},
   "source": [
    "### Computing Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a416ab-aae1-456b-b659-69778e813e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()  # calc derivatives\n",
    "print(w)\n",
    "print(w.grad)\n",
    "print(b)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8dfc31-a047-493b-a83e-ae97f91ba2da",
   "metadata": {},
   "source": [
    "### Disabling Gradient Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0394dd64-3715-4cc4-a88d-187df826190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.matmul(x, w) + b\n",
    "print(z.requires_grad)\n",
    "\n",
    "# 順方向の計算結果のみが必要な場合\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w) + b\n",
    "print(z.requires_grad)\n",
    "\n",
    "# another way\n",
    "z = torch.matmul(x, w) + b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c46a179-159e-4706-a13e-fabe28d7224c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7314fc2d-7217-4332-b81d-efc396d33d2c",
   "metadata": {},
   "source": [
    "## OPTIMIZING MODEL PARAMETERS\n",
    "- https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaf8d25-3905-4f06-8307-a1d455721825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import Lambda, ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\", train=True, download=True, transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\", train=False, download=True, transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a93e8eb-7395-42e8-8a2a-91972a57a66c",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0914ba50-f001-4b61-aba3-6a2de562ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599988dc-fa78-4d11-9972-e2a646a0029f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optimization Loop\n",
    "- epoch\n",
    "  - The Train Loop - iterate over the training dataset and try to converge to optimal parameters.\n",
    "  - The Validation/Test Loop - iterate over the test dataset to check if model performance is improving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f592071b-aa6d-4c4d-9eb2-1c66a66900b8",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7ba9f4-88dc-4b5e-adf5-df6b4aea67bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3e46e5-aced-4883-8abb-f955d6f6a92d",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "- `optimizer.zero_grad()`: 勾配の初期化\n",
    "- `loss.backward()`: bp\n",
    "- `optimizer.step()`: update params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63571fa-89ce-43aa-936f-a45c1a88ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9fc5c2-7823-4fc6-a266-4d3bff52c94c",
   "metadata": {},
   "source": [
    "### Full Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5e9ae8-229e-4991-983a-d85db51bdc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(\n",
    "        f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcf8e57-6dc3-472b-9d0b-3d8888448093",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb93d4cd-f271-400b-a00c-2fa04a3f350f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
